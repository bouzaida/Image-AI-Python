{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course:  Convolutional Neural Networks for Image Classification\n",
    "\n",
    "## Section-7\n",
    "### What is next?\n",
    "#### Tensorboard callback\n",
    "\n",
    "**Description:**  \n",
    "*Train designed deep CNN models with callback to collect log data for Tensorboard  \n",
    "Run Tensorboad*  \n",
    "\n",
    "**File:** *what_is_next_part_2.ipynb*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm:\n",
    "\n",
    "**--> Step 1:** Open preprocessed dataset  \n",
    "**--> Step 2:** Load saved 1st deep CNN model  \n",
    "**--> Step 3:** Define callback and train loaded model  \n",
    "\n",
    "\n",
    "**Result:**  \n",
    "- log data to visualize Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing needed libraries\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, Callback, TensorBoard\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing needed libraries\n",
    "# import numpy as np\n",
    "# import h5py\n",
    "\n",
    "\n",
    "# from keras.models import load_model\n",
    "# from keras.utils.np_utils import to_categorical\n",
    "# from keras.callbacks import LearningRateScheduler, ModelCheckpoint, Callback\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up full path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full or absolute path to 'Section4' with preprocessed datasets\n",
    "# (!) On Windows, the path should look like following:\n",
    "# r'C:\\Users\\your_name\\PycharmProjects\\CNNCourse\\Section4'\n",
    "# or:\n",
    "# 'C:\\\\Users\\\\your_name\\\\PycharmProjects\\\\CNNCourse\\\\Section4'\n",
    "full_path_to_Section4 = \\\n",
    "    '/home/valentyn/PycharmProjects/CNNCourse/Section4'\n",
    "\n",
    "\n",
    "# Full or absolute path to 'Section5' with designed models\n",
    "# (!) On Windows, the path should look like following:\n",
    "# r'C:\\Users\\your_name\\PycharmProjects\\CNNCourse\\Section5'\n",
    "# or:\n",
    "# 'C:\\\\Users\\\\your_name\\\\PycharmProjects\\\\CNNCourse\\\\Section5'\n",
    "full_path_to_Section5 = \\\n",
    "    '/home/valentyn/PycharmProjects/CNNCourse/Section5'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traffic Signs, 1st RGB model\n",
    "### RGB dataset (255.0 ==> mean)\n",
    "\n",
    "## Step 1: Opening preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening saved Traffic Signs dataset from HDF5 binary file\n",
    "# Initiating File object\n",
    "# Opening file in reading mode by 'r'\n",
    "# (!) On Windows, it might need to change\n",
    "# this: + '/' +\n",
    "# to this: + '\\' +\n",
    "# or to this: + '\\\\' +\n",
    "with h5py.File(full_path_to_Section4 + '/' + \n",
    "               'ts' + '/' +\n",
    "               'dataset_ts_rgb_255_mean.hdf5', 'r') as f:\n",
    "    # Showing all keys in the HDF5 binary file\n",
    "    print(list(f.keys()))\n",
    "    \n",
    "    # Extracting saved arrays for training by appropriate keys\n",
    "    # Saving them into new variables    \n",
    "    x_train = f['x_train']  # HDF5 dataset\n",
    "    y_train = f['y_train']  # HDF5 dataset\n",
    "    # Converting them into Numpy arrays\n",
    "    x_train = np.array(x_train)  # Numpy arrays\n",
    "    y_train = np.array(y_train)  # Numpy arrays\n",
    "    \n",
    "    \n",
    "    # Extracting saved arrays for validation by appropriate keys\n",
    "    # Saving them into new variables \n",
    "    x_validation = f['x_validation']  # HDF5 dataset\n",
    "    y_validation = f['y_validation']  # HDF5 dataset\n",
    "    # Converting them into Numpy arrays\n",
    "    x_validation = np.array(x_validation)  # Numpy arrays\n",
    "    y_validation = np.array(y_validation)  # Numpy arrays\n",
    "    \n",
    "    \n",
    "    # Extracting saved arrays for testing by appropriate keys\n",
    "    # Saving them into new variables \n",
    "    x_test = f['x_test']  # HDF5 dataset\n",
    "    y_test = f['y_test']  # HDF5 dataset\n",
    "    # Converting them into Numpy arrays\n",
    "    x_test = np.array(x_test)  # Numpy arrays\n",
    "    y_test = np.array(y_test)  # Numpy arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing types of loaded arrays\n",
    "print(type(x_train))\n",
    "print(type(y_train))\n",
    "print(type(x_validation))\n",
    "print(type(y_validation))\n",
    "print(type(x_test))\n",
    "print(type(y_test))\n",
    "print()\n",
    "\n",
    "\n",
    "# Showing shapes of loaded arrays\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_validation.shape)\n",
    "print(y_validation.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing class index from the vector\n",
    "print('Class index from vector:', y_train[5])\n",
    "print()\n",
    "\n",
    "# Preparing classes to be passed into the model\n",
    "# Transforming them from vectors to binary matrices\n",
    "# It is needed to set relationship between classes to be understood by the algorithm\n",
    "# Such format is commonly used in training and predicting\n",
    "y_train = to_categorical(y_train, num_classes = 43)\n",
    "y_validation = to_categorical(y_validation, num_classes = 43)\n",
    "\n",
    "\n",
    "# Showing shapes of converted vectors into matrices\n",
    "print(y_train.shape)\n",
    "print(y_validation.shape)\n",
    "print(y_test.shape)\n",
    "print()\n",
    "\n",
    "\n",
    "# Showing class index from the matrix\n",
    "print('Class index from matrix:', y_train[5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traffic Signs, 1st RGB model\n",
    "### RGB dataset (255.0 ==> mean)\n",
    "\n",
    "## Step 2: Loading saved 1st model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading 1st model for Traffic Signs dataset\n",
    "# (!) On Windows, it might need to change\n",
    "# this: + '/' +\n",
    "# to this: + '\\' +\n",
    "# or to this: + '\\\\' +\n",
    "model_rgb = load_model(full_path_to_Section5 + '/' + 'ts' + '/' + 'model_1_ts_rgb.h5')\n",
    "\n",
    "\n",
    "# Check point\n",
    "print('Model is successfully loaded')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traffic Signs, 1st RGB model\n",
    "### RGB dataset (255.0 ==> mean)\n",
    "\n",
    "## Step 3: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining number of epochs\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "# Defining schedule to update learning rate\n",
    "learning_rate = LearningRateScheduler(lambda x: 1e-2 * 0.95 ** (x + epochs), verbose=1)\n",
    "\n",
    "\n",
    "# Check point\n",
    "print('Number of epochs and schedule for learning rate are set successfully')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To resolve following issue:\n",
    "'''ProfilerNotRunningError: Cannot stop profiling. No profiler is running'''\n",
    "# Look for solutions here:\n",
    "# https://github.com/tensorflow/tensorboard/issues/2819\n",
    "\n",
    "\n",
    "# Preparing Tensorboard callback to collect log data\n",
    "# (!) On Windows, it might need to change\n",
    "# this: + '/' +\n",
    "# to this: + '\\' +\n",
    "# or to this: + '\\\\' +\n",
    "tensorboard_callback = TensorBoard(log_dir='ts' + '/' + 'logs',\n",
    "                                   histogram_freq=1,\n",
    "                                   write_graph=True,\n",
    "                                   write_images=True,\n",
    "                                   update_freq='epoch',                                   \n",
    "                                   profile_batch = 100000000,\n",
    "                                   embeddings_freq=0,\n",
    "                                   embeddings_metadata=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# If you're using Nvidia GPU and 'cnngpu' environment, there might be an issue like:\n",
    "'''Failed to get convolution algorithm. This is probably because cuDNN failed to initialize'''\n",
    "# In this case, close all Jupyter Notebooks, close Terminal Window or Anaconda Prompt\n",
    "# Open again just this one Jupyter Notebook and run it\n",
    "\n",
    "\n",
    "# Training model\n",
    "h = model_rgb.fit(x_train, y_train,\n",
    "                  batch_size=50,\n",
    "                  epochs=epochs,\n",
    "                  validation_data=(x_validation, y_validation),\n",
    "                  callbacks=[learning_rate, tensorboard_callback],\n",
    "                  verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some comments\n",
    "\n",
    "To get more details for usage of 'TensorBoard':  \n",
    "**print(help(TensorBoard))**\n",
    "  \n",
    "More details and examples are here:  \n",
    " - https://keras.io/api/callbacks/tensorboard/  \n",
    " - https://tensorflow.org/get_started/summaries_and_tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(help(TensorBoard))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
