{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course:  Convolutional Neural Networks for Image Classification\n",
    "\n",
    "## Section-8\n",
    "### Augment and equalize images in dataset\n",
    "\n",
    "**Description:**  \n",
    "*Add transformed images into dataset  \n",
    "Make number of images equal for all classes  \n",
    "Plot equalized histogram*  \n",
    "\n",
    "**File:** *augment_and_equalize.ipynb*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm:\n",
    "\n",
    "**--> Step 1:** Open Traffic Signs dataset  \n",
    "**--> Step 2:** Concatenate arrays  \n",
    "**--> Step 3:** Define functions for augmentation  \n",
    "**--> Step 4:** Implement augmentation and equalization  \n",
    "**--> Step 5:** Concatenating temporary arrays to main arrays  \n",
    "**--> Step 6:** Plot histogram to show distribution  \n",
    "**--> Step 7:** Shuffle data along the first axis  \n",
    "**--> Step 8:** Split arrays into train, validation and test  \n",
    "**--> Step 9:** Save final Numpy arrays into one HDF5 binary file  \n",
    "**--> Step 10:** Visualize 100 examples  \n",
    "\n",
    "\n",
    "**Result:**  \n",
    "- HDF5 binary file with augmented Traffic Signs dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing needed libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import cv2\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "# Importing library to see calculation progress inside loops in Real Time\n",
    "# To install, use following command: pip install tqdm\n",
    "# Don't forget to activate environment in which you're working\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up full path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full or absolute path to 'Section3' with Traffic Signs dataset\n",
    "# (!) On Windows, the path should look like following:\n",
    "# r'C:\\Users\\your_name\\PycharmProjects\\CNNCourse\\Section3'\n",
    "# or:\n",
    "# 'C:\\\\Users\\\\your_name\\\\PycharmProjects\\\\CNNCourse\\\\Section3'\n",
    "full_path_to_Section3 = \\\n",
    "    '/home/valentyn/PycharmProjects/CNNCourse/Section3'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Opening Traffic Signs dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening saved Traffic Signs dataset from HDF5 binary file\n",
    "# Initiating File object\n",
    "# Opening file in reading mode by 'r'\n",
    "# (!) On Windows, it might need to change\n",
    "# this: + '/' +\n",
    "# to this: + '\\' +\n",
    "# or to this: + '\\\\' +\n",
    "with h5py.File(full_path_to_Section3 + '/' + 'dataset_ts.hdf5', 'r') as f:\n",
    "    # Extracting saved arrays for training by appropriate keys\n",
    "    # Saving them into new variables\n",
    "    x_train = f['x_train']  # HDF5 dataset\n",
    "    y_train = f['y_train']  # HDF5 dataset\n",
    "    # Converting them into Numpy arrays\n",
    "    x_train = np.array(x_train)  # Numpy arrays\n",
    "    y_train = np.array(y_train)  # Numpy arrays\n",
    "\n",
    "    # Extracting saved arrays for validation by appropriate keys\n",
    "    # Saving them into new variables\n",
    "    x_validation = f['x_validation']  # HDF5 dataset\n",
    "    y_validation = f['y_validation']  # HDF5 dataset\n",
    "    # Converting them into Numpy arrays\n",
    "    x_validation = np.array(x_validation)  # Numpy arrays\n",
    "    y_validation = np.array(y_validation)  # Numpy arrays\n",
    "\n",
    "    # Extracting saved arrays for testing by appropriate keys\n",
    "    # Saving them into new variables\n",
    "    x_test = f['x_test']  # HDF5 dataset\n",
    "    y_test = f['y_test']  # HDF5 dataset\n",
    "    # Converting them into Numpy arrays\n",
    "    x_test = np.array(x_test)  # Numpy arrays\n",
    "    y_test = np.array(y_test)  # Numpy arrays\n",
    "\n",
    "\n",
    "# Check point\n",
    "print('Traffic Signs dataset is successfully opened')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check point\n",
    "# Showing shapes of loaded arrays\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_validation.shape)\n",
    "print(y_validation.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Concatenating arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating arrays vertically\n",
    "x_train = np.concatenate((x_train, x_validation, x_test), axis=0)\n",
    "y_train = np.concatenate((y_train, y_validation, y_test), axis=0)\n",
    "\n",
    "\n",
    "# Check point\n",
    "# Showing shapes of concatenated arrays\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Defining functions for augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function for changing brightness\n",
    "def brightness_changing(input_image):\n",
    "    # Converting input image from RGB to HSV colour space\n",
    "    image_hsv = cv2.cvtColor(input_image, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    # Defining random value (positive or negative) for changing brightness\n",
    "    # To make image darker or brighter\n",
    "    n = np.random.choice([-1, 1])\n",
    "    \n",
    "    # Checking if n is negative\n",
    "    if n == -1:\n",
    "        # Preparing value to darken image with\n",
    "        random_brightness = n * np.random.randint(low=5, high=10)\n",
    "        \n",
    "    # Otherwise, if n is positive\n",
    "    elif n == 1:\n",
    "        # Preparing value to brighten image with\n",
    "        random_brightness = np.random.randint(low=50, high=75)\n",
    "    \n",
    "    # Changing Value channel for HSV image\n",
    "    image_hsv[:, :, 2] += random_brightness\n",
    "    \n",
    "    # To exclude pixels' values that are less than 0 and more than 255,\n",
    "    # Numpy function 'clip' is applied\n",
    "    # It keeps values of array in the given range\n",
    "    # And it replaces non-needed values with boundary numbers\n",
    "    image_hsv[:, :, 2] = np.clip(image_hsv[:, :, 2], 0, 255)\n",
    "    \n",
    "    # Converting resulted HSV image back to RGB colour space\n",
    "    image_rgb = cv2.cvtColor(image_hsv, cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "    # Returning resulted image with changed brightness\n",
    "    return image_rgb\n",
    "\n",
    "\n",
    "# Check point\n",
    "print('Function to randomly change brightness is successfully defined')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function to rotate image around centre point\n",
    "def rotation_changing(input_image):\n",
    "    # Defining random angle for rotation (positive or negative)\n",
    "    angle = np.random.randint(low=5, high=15) * np.random.choice([-1, 1])\n",
    "    \n",
    "    # Getting shape of input image\n",
    "    height, width, channels = input_image.shape\n",
    "    \n",
    "    # Calculating coordinates (x, y) for centre point of input image\n",
    "    centre_point = (int(width / 2), int(height / 2))\n",
    "    \n",
    "    # Calculating Affine Matrix\n",
    "    affine_matrix = cv2.getRotationMatrix2D(centre_point, angle, scale=1)\n",
    "    \n",
    "    # Warping original image with Affine Matrix\n",
    "    rotated_image = cv2.warpAffine(input_image, affine_matrix, (height, width))\n",
    "    \n",
    "    # Returning rotated image\n",
    "    return rotated_image\n",
    "\n",
    "\n",
    "# Check point\n",
    "print('Function to randomly rotate image is successfully defined')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function to project image\n",
    "# by coordinates of quadrangle vertices\n",
    "def perspective_changing_1(input_image):\n",
    "    # Getting shape of input image\n",
    "    height, width, channels = input_image.shape\n",
    "    \n",
    "    # Defining variables for vertices of input image\n",
    "    x_min = 0\n",
    "    y_min = 0\n",
    "    x_max = width\n",
    "    y_max = height\n",
    "    \n",
    "    # Prepering coordinates of quadrangle vertices\n",
    "    # in the input image\n",
    "    src = np.float32([[x_min, y_min],  # top-left\n",
    "                      [x_max, y_min],  # top-right\n",
    "                      [x_min, y_max],  # bottom-left\n",
    "                      [x_max, y_max]]) # bottom-right\n",
    "    \n",
    "    # Preparing coordinates of corresponding quadrangle vertices\n",
    "    # in the output image\n",
    "    dst = np.float32([[x_min + 5, y_min + 5],  # top-left\n",
    "                      [x_max - 5, y_min + 5],  # top-right\n",
    "                      [x_min, y_max],          # bottom-left\n",
    "                      [x_max, y_max]])         # bottom-right\n",
    "    \n",
    "    # Calculating perspective transformation matrix\n",
    "    # from 4 pairs of the corresponding points\n",
    "    matrix = cv2.getPerspectiveTransform(src, dst)\n",
    "    \n",
    "    # Applying perspective transformation\n",
    "    # by found matrix to input image\n",
    "    projected_image = cv2.warpPerspective(input_image, matrix, (height, width))\n",
    "    \n",
    "    # Returning projected image\n",
    "    return projected_image\n",
    "\n",
    "\n",
    "# Check point\n",
    "print('First function to project image is successfully defined')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function to project image\n",
    "# by coordinates of quadrangle vertices\n",
    "def perspective_changing_2(input_image):\n",
    "    # Getting shape of input image\n",
    "    height, width, channels = input_image.shape\n",
    "    \n",
    "    # Defining variables for vertices of input image\n",
    "    x_min = 0\n",
    "    y_min = 0\n",
    "    x_max = width\n",
    "    y_max = height\n",
    "    \n",
    "    # Prepering coordinates of quadrangle vertices\n",
    "    # in the input image\n",
    "    src = np.float32([[x_min, y_min],  # top-left\n",
    "                      [x_max, y_min],  # top-right\n",
    "                      [x_min, y_max],  # bottom-left\n",
    "                      [x_max, y_max]]) # bottom-right\n",
    "    \n",
    "    # Preparing coordinates of corresponding quadrangle vertices\n",
    "    # in the output image\n",
    "    dst = np.float32([[x_min, y_min],          # top-left\n",
    "                      [x_max - 5, y_min + 5],  # top-right\n",
    "                      [x_min, y_max],          # bottom-left\n",
    "                      [x_max - 5, y_max - 5]]) # bottom-right\n",
    "    \n",
    "    # Calculating perspective transformation matrix\n",
    "    # from 4 pairs of the corresponding points\n",
    "    matrix = cv2.getPerspectiveTransform(src, dst)\n",
    "    \n",
    "    # Applying perspective transformation\n",
    "    # by found matrix to input image\n",
    "    projected_image = cv2.warpPerspective(input_image, matrix, (height, width))\n",
    "    \n",
    "    # Returning projected image\n",
    "    return projected_image\n",
    "\n",
    "\n",
    "# Check point\n",
    "print('Second function to project image is successfully defined')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Implementing augmentation and equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating number of images for every class\n",
    "# Iterating all classes' indexes in 'y_train' array\n",
    "# Using Numpy function 'unique'\n",
    "# Returning sorted unique elements and their frequencies\n",
    "classesIndexes, classesFrequency = np.unique(y_train, return_counts=True)\n",
    "\n",
    "\n",
    "# Printing frequency (number of images) for every class\n",
    "print('classes indexes:' , classesIndexes)\n",
    "print()\n",
    "print('classes frequency:', classesFrequency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating all 43 classes\n",
    "for i in range(len(classesIndexes)):\n",
    "    # Option 1\n",
    "    # Calculating how many examples is needed to add for current class\n",
    "    # number_of_examples_to_add = int(1000000 / 43) - classesFrequency[i]\n",
    "    # print('Class {0:02d} needs following number of images: {1}'.format(i, number_of_examples_to_add))\n",
    "    \n",
    "    # Option 2\n",
    "    # Calculating how many examples is needed to add for current class\n",
    "    number_of_examples_to_add = np.max(classesFrequency) + 10 - classesFrequency[i]\n",
    "    # print('Class {0:02d} needs following number of images: {1}'.format(i, number_of_examples_to_add))\n",
    "    \n",
    "    # Preparing lists for collecting new images\n",
    "    x_temp = []\n",
    "    y_temp = []\n",
    "    \n",
    "    # Augmenting current class\n",
    "    # Wrapping the loop with 'tqdm' in order to see the progress in Real Time\n",
    "    for j in tqdm(range(number_of_examples_to_add)):\n",
    "        # Getting indexes of images for current class in 'y_train' array\n",
    "        image_indexes = np.where(y_train == i)  # tuple with array of needed indexes\n",
    "        \n",
    "        # Extracting only array itself\n",
    "        image_indexes = image_indexes[0]  # Numpy array with needed indexes\n",
    "        # print(image_indexes.shape)\n",
    "        # print(image_indexes)\n",
    "        \n",
    "        # Defining random value to get random image\n",
    "        n = np.random.randint(low=0, high=classesFrequency[i])\n",
    "        \n",
    "        # Getting random image from current class\n",
    "        random_image = np.copy(x_train[image_indexes[n]])\n",
    "        \n",
    "        # Applying random brightness changing\n",
    "        random_image = brightness_changing(random_image)\n",
    "        \n",
    "        # Choosing transformation technique\n",
    "        m = np.random.choice([1, 2, 3])\n",
    "        \n",
    "        # Applying rotation around centre point\n",
    "        if m == 1:\n",
    "            random_image = rotation_changing(random_image)\n",
    "        \n",
    "        # Applying perspective transformation 1\n",
    "        elif m == 2:\n",
    "            random_image = perspective_changing_1(random_image)\n",
    "        \n",
    "        # Applying perspective transformation 2\n",
    "        elif m == 3:\n",
    "            random_image = perspective_changing_2(random_image)\n",
    "        \n",
    "        # Appending transformed image into the list\n",
    "        x_temp.append(random_image)\n",
    "        y_temp.append(i)\n",
    "    \n",
    "    # Converting lists into Numpy arrays\n",
    "    x_temp = np.array(x_temp)  # Numpy arrays\n",
    "    y_temp = np.array(y_temp)  # Numpy arrays\n",
    "    \n",
    "    # Saving prepared Numpy arrays into HDF5 binary file\n",
    "    # for currently augmented class\n",
    "    # Initiating File object\n",
    "    # Creating files with names from '00.hdf5' to '42.hdf5'\n",
    "    # Opening them in writing mode by 'w'\n",
    "    # (!) On Windows, it might need to change\n",
    "    # this: + '/' +\n",
    "    # to this: + '\\' +\n",
    "    # or to this: + '\\\\' +\n",
    "    with h5py.File('ts' + '/' + '{0:02d}'.format(i) + '.hdf5', 'w') as f:\n",
    "        # Calling methods to create datasets of given shapes and types\n",
    "        # Saving Numpy arrays for training\n",
    "        f.create_dataset('x_temp', data=x_temp, dtype='f')\n",
    "        f.create_dataset('y_temp', data=y_temp, dtype='i')\n",
    "\n",
    "\n",
    "# Check point\n",
    "print('Augmentation is successfully finished')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Concatenating temporary arrays to main arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Iterating all saved augmented classes\n",
    "for i in range(43):\n",
    "    # Opening saved binary file with current augmented classes\n",
    "    # (!) On Windows, it might need to change\n",
    "    # this: + '/' +\n",
    "    # to this: + '\\' +\n",
    "    # or to this: + '\\\\' +\n",
    "    with h5py.File('ts' + '/' + '{0:02d}'.format(i) + '.hdf5', 'r') as f:\n",
    "        # Extracting saved arrays by appropriate keys\n",
    "        # Saving them into new variables\n",
    "        x_temp = f['x_temp']  # HDF5 dataset\n",
    "        y_temp = f['y_temp']  # HDF5 dataset\n",
    "        # Converting them into Numpy arrays\n",
    "        x_temp = np.array(x_temp)  # Numpy arrays\n",
    "        y_temp = np.array(y_temp)  # Numpy arrays\n",
    "    \n",
    "    \n",
    "    # Concatenating vertically temp arrays to main arrays\n",
    "    x_train = np.concatenate((x_train, x_temp), axis=0)\n",
    "    y_train = np.concatenate((y_train, y_temp), axis=0)\n",
    "    \n",
    "    \n",
    "    # Check point\n",
    "    print('{0:02d} class is successfully concatenated'.format(i))\n",
    "\n",
    "\n",
    "# Check point\n",
    "print()\n",
    "print('Concatenation is successfully finished')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Plotting histogram to show distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic function that renders the figure in a jupyter notebook\n",
    "# instead of displaying a figure object\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Setting default size of the plot\n",
    "plt.rcParams['figure.figsize'] = (10.0, 7.0)\n",
    "\n",
    "\n",
    "# Calculating number of images for every class\n",
    "# Iterating all classes' indexes in 'y_train' array\n",
    "# Using Numpy function 'unique'\n",
    "# Returning sorted unique elements and their frequencies\n",
    "classesIndexes, classesFrequency = np.unique(y_train, return_counts=True)\n",
    "\n",
    "\n",
    "# Printing frequency (number of images) for every class\n",
    "print('classes indexes:' , classesIndexes)\n",
    "print()\n",
    "print('classes frequency:', classesFrequency)\n",
    "\n",
    "\n",
    "# Plotting histogram of 43 classes with their number of images\n",
    "# Defining a figure object \n",
    "figure = plt.figure()\n",
    "\n",
    "\n",
    "# Plotting Bar chart\n",
    "plt.bar(classesIndexes, classesFrequency, align='center', alpha=0.6)\n",
    "\n",
    "\n",
    "# Giving name to Y axis\n",
    "plt.ylabel('Class frequency', fontsize=16)\n",
    "\n",
    "\n",
    "# Giving names to every Bar along X axis\n",
    "plt.xticks(classesIndexes, fontsize=9)\n",
    "\n",
    "\n",
    "# Giving name to the plot\n",
    "plt.title('Histogram of Traffic Signs Dataset', fontsize=20)\n",
    "\n",
    "\n",
    "# Saving the plot\n",
    "figure.savefig('histogram_ts_images.png')\n",
    "\n",
    "\n",
    "# Showing the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Shuffling data along the first axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling data along the first axis\n",
    "# Saving appropriate connection: image --> label\n",
    "x_train, y_train = shuffle(x_train, y_train)\n",
    "\n",
    "\n",
    "# Check point\n",
    "print('Shuffling is successfully finished')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Splitting arrays into train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing first 30% of elements from Numpy arrays for training\n",
    "# Assigning sliced elements to temp Numpy arrays\n",
    "x_temp = x_train[:int(x_train.shape[0] * 0.3), :, :, :]\n",
    "y_temp = y_train[:int(y_train.shape[0] * 0.3)]\n",
    "\n",
    "\n",
    "# Slicing last 70% of elements from Numpy arrays for training\n",
    "# Re-assigning sliced elements to train Numpy arrays\n",
    "x_train = x_train[int(x_train.shape[0] * 0.3):, :, :, :]\n",
    "y_train = y_train[int(y_train.shape[0] * 0.3):]\n",
    "\n",
    "\n",
    "# Slicing first 80% of elements from temp Numpy arrays\n",
    "# Assigning sliced elements to validation Numpy arrays\n",
    "x_validation = x_temp[:int(x_temp.shape[0] * 0.8), :, :, :]\n",
    "y_validation = y_temp[:int(y_temp.shape[0] * 0.8)]\n",
    "\n",
    "\n",
    "# Slicing last 20% of elements from temp Numpy arrays\n",
    "# Assigning sliced elements to test Numpy arrays\n",
    "x_test = x_temp[int(x_temp.shape[0] * 0.8):, :, :, :]\n",
    "y_test = y_temp[int(y_temp.shape[0] * 0.8):]\n",
    "\n",
    "\n",
    "# Check point\n",
    "print('Splitting is successfully finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check point\n",
    "# Showing shapes of arrays after splitting\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_validation.shape)\n",
    "print(y_validation.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Saving final Numpy arrays into one HDF5 binary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving prepared Numpy arrays into one HDF5 binary file\n",
    "# Initiating File object\n",
    "# Creating file with name 'dataset_ts_rgb_augmented.hdf5'\n",
    "# Opening it in writing mode by 'w'\n",
    "# (!) On Windows, it might need to change\n",
    "# this: + '/' +\n",
    "# to this: + '\\' +\n",
    "# or to this: + '\\\\' +\n",
    "with h5py.File('ts' + '/' + 'dataset_ts_rgb_augmented.hdf5', 'w') as f:\n",
    "    # Calling methods to create datasets of given shapes and types\n",
    "    # Saving Numpy arrays for training\n",
    "    f.create_dataset('x_train', data=x_train, dtype='f')\n",
    "    f.create_dataset('y_train', data=y_train, dtype='i')\n",
    "\n",
    "    # Saving Numpy arrays for validation\n",
    "    f.create_dataset('x_validation', data=x_validation, dtype='f')\n",
    "    f.create_dataset('y_validation', data=y_validation, dtype='i')\n",
    "\n",
    "    # Saving Numpy arrays for testing\n",
    "    f.create_dataset('x_test', data=x_test, dtype='f')\n",
    "    f.create_dataset('y_test', data=y_test, dtype='i')\n",
    "\n",
    "\n",
    "# Check point\n",
    "print('Saving is successfully finished')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Visualizing 100 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Magic function that renders the figure in a jupyter notebook\n",
    "# instead of displaying a figure object\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Setting default size of the plot\n",
    "plt.rcParams['figure.figsize'] = (10.0, 60.0)\n",
    "\n",
    "\n",
    "# Defining a figure object with number of needed subplots\n",
    "# ax is a (25, 4) Numpy array\n",
    "# To access specific subplot we call it by ax[0, 0]\n",
    "figure, ax = plt.subplots(nrows=25, ncols=4)\n",
    "\n",
    "\n",
    "# Plotting 100 examples along 25 rows and 4 columns\n",
    "for i in range(25):\n",
    "    for j in range(4):\n",
    "        # Preparing random index\n",
    "        ii = np.random.randint(low=0, high=x_train.shape[0])\n",
    "        \n",
    "        # Plotting current subplot\n",
    "        ax[i, j].imshow(x_train[ii].astype('uint8'))\n",
    "        \n",
    "        # Giving name to current subplot\n",
    "        # according to class's name in list 'labels'\n",
    "        ax[i, j].set_title('Class ' + str(y_train[ii]), fontsize=16)\n",
    "        \n",
    "        # Hiding axis\n",
    "        ax[i, j].axis('off')\n",
    "\n",
    "\n",
    "# Adjusting distance between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Showing the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some comments\n",
    "\n",
    "To get more details for usage of 'np.copy':  \n",
    "**print(help(np.copy))**\n",
    "  \n",
    "More details and examples are here:  \n",
    " - https://numpy.org/doc/stable/reference/generated/numpy.copy.html  \n",
    "\n",
    "\n",
    "To get more details for usage of 'np.where':  \n",
    "**print(help(np.where))**\n",
    "  \n",
    "More details and examples are here:  \n",
    " - https://numpy.org/doc/stable/reference/generated/numpy.where.html  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(help(np.copy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(help(np.where))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
