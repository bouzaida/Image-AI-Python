{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course:  Convolutional Neural Networks for Image Classification\n",
    "\n",
    "## Section-8\n",
    "### Manipulate images by geometric transformations\n",
    "\n",
    "**Description:**  \n",
    "*Generate additional images by rotation and projection  \n",
    "Plot resulted images*  \n",
    "\n",
    "**File:** *geometric_transformations.ipynb*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm:\n",
    "\n",
    "**--> Step 1:** Open Traffic Signs dataset  \n",
    "**--> Step 2:** Apply rotation around centre point  \n",
    "**--> Step 3:** Apply perspective transformations  \n",
    "**--> Step 4:** Visualize examples  \n",
    "\n",
    "\n",
    "**Result:**  \n",
    "- Plot with images before and after geometric transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing needed libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up full path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full or absolute path to 'Section3' with Traffic Signs dataset\n",
    "# (!) On Windows, the path should look like following:\n",
    "# r'C:\\Users\\your_name\\PycharmProjects\\CNNCourse\\Section3'\n",
    "# or:\n",
    "# 'C:\\\\Users\\\\your_name\\\\PycharmProjects\\\\CNNCourse\\\\Section3'\n",
    "full_path_to_Section3 = \\\n",
    "    '/home/valentyn/PycharmProjects/CNNCourse/Section3'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Opening Traffic Signs dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening saved Traffic Signs dataset from HDF5 binary file\n",
    "# Initiating File object\n",
    "# Opening file in reading mode by 'r'\n",
    "# (!) On Windows, it might need to change\n",
    "# this: + '/' +\n",
    "# to this: + '\\' +\n",
    "# or to this: + '\\\\' +\n",
    "with h5py.File(full_path_to_Section3 + '/' + 'dataset_ts.hdf5', 'r') as f:\n",
    "    # Extracting saved arrays for training by appropriate keys\n",
    "    # Saving them into new variables\n",
    "    x_train = f['x_train']  # HDF5 dataset\n",
    "    y_train = f['y_train']  # HDF5 dataset\n",
    "    # Converting them into Numpy arrays\n",
    "    x_train = np.array(x_train)  # Numpy arrays\n",
    "    y_train = np.array(y_train)  # Numpy arrays\n",
    "\n",
    "\n",
    "# Check point\n",
    "print('Traffic Signs dataset is successfully opened')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check point\n",
    "# Showing shapes of loaded arrays\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Applying rotation around centre point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function to rotate image around centre point\n",
    "def rotation_changing(input_image):\n",
    "    # Defining random angle for rotation (positive or negative)\n",
    "    angle = np.random.randint(low=5, high=15) * np.random.choice([-1, 1])\n",
    "    \n",
    "    # Getting shape of input image\n",
    "    height, width, channels = input_image.shape\n",
    "    \n",
    "    # Calculating coordinates (x, y) for centre point of input image\n",
    "    centre_point = (int(width / 2), int(height / 2))\n",
    "    \n",
    "    # Calculating Affine Matrix\n",
    "    affine_matrix = cv2.getRotationMatrix2D(centre_point, angle, scale=1)\n",
    "    \n",
    "    # Check point\n",
    "    # Showing shape of calculated rotation matrix and its values\n",
    "    print(affine_matrix.shape)  # (2, 3)\n",
    "    print(affine_matrix)\n",
    "    \n",
    "    # Warping original image with Affine Matrix\n",
    "    rotated_image = cv2.warpAffine(input_image, affine_matrix, (height, width))\n",
    "    \n",
    "    # Returning rotated image\n",
    "    return rotated_image\n",
    "\n",
    "\n",
    "# Check point\n",
    "print('Function to randomly rotate image is successfully defined')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic function that renders the figure in a jupyter notebook\n",
    "# instead of displaying a figure object\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(rotation_changing(x_train[6]).astype('uint8'))\n",
    "\n",
    "# Showing the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Applying perspective transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function to project image\n",
    "# by coordinates of quadrangle vertices\n",
    "def perspective_changing_1(input_image):\n",
    "    # Getting shape of input image\n",
    "    height, width, channels = input_image.shape\n",
    "    \n",
    "    # Defining variables for vertices of input image\n",
    "    x_min = 0\n",
    "    y_min = 0\n",
    "    x_max = width\n",
    "    y_max = height\n",
    "    \n",
    "    # Prepering coordinates of quadrangle vertices\n",
    "    # in the input image\n",
    "    src = np.float32([[x_min, y_min],  # top-left\n",
    "                      [x_max, y_min],  # top-right\n",
    "                      [x_min, y_max],  # bottom-left\n",
    "                      [x_max, y_max]]) # bottom-right\n",
    "    \n",
    "    # Preparing coordinates of corresponding quadrangle vertices\n",
    "    # in the output image\n",
    "    dst = np.float32([[x_min + 5, y_min + 5],  # top-left\n",
    "                      [x_max - 5, y_min + 5],  # top-right\n",
    "                      [x_min, y_max],          # bottom-left\n",
    "                      [x_max, y_max]])         # bottom-right\n",
    "    \n",
    "    # Calculating perspective transformation matrix\n",
    "    # from 4 pairs of the corresponding points\n",
    "    matrix = cv2.getPerspectiveTransform(src, dst)\n",
    "    \n",
    "    # Check point\n",
    "    # Showing shape of calculated perspective matrix and its values\n",
    "    print(matrix.shape)  # (3, 3)\n",
    "    print(matrix)\n",
    "    \n",
    "    # Applying perspective transformation\n",
    "    # by found matrix to input image\n",
    "    projected_image = cv2.warpPerspective(input_image, matrix, (height, width))\n",
    "       \n",
    "    # Returning projected image\n",
    "    return projected_image\n",
    "\n",
    "\n",
    "# Check point\n",
    "print('First function to project image is successfully defined')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function to project image\n",
    "# by coordinates of quadrangle vertices\n",
    "def perspective_changing_2(input_image):\n",
    "    # Getting shape of input image\n",
    "    height, width, channels = input_image.shape\n",
    "    \n",
    "    # Defining variables for vertices of input image\n",
    "    x_min = 0\n",
    "    y_min = 0\n",
    "    x_max = width\n",
    "    y_max = height\n",
    "    \n",
    "    # Prepering coordinates of quadrangle vertices\n",
    "    # in the input image\n",
    "    src = np.float32([[x_min, y_min],  # top-left\n",
    "                      [x_max, y_min],  # top-right\n",
    "                      [x_min, y_max],  # bottom-left\n",
    "                      [x_max, y_max]]) # bottom-right\n",
    "    \n",
    "    # Preparing coordinates of corresponding quadrangle vertices\n",
    "    # in the output image\n",
    "    dst = np.float32([[x_min, y_min],          # top-left\n",
    "                      [x_max - 5, y_min + 5],  # top-right\n",
    "                      [x_min, y_max],          # bottom-left\n",
    "                      [x_max - 5, y_max - 5]]) # bottom-right\n",
    "    \n",
    "    # Calculating perspective transformation matrix\n",
    "    # from 4 pairs of the corresponding points\n",
    "    matrix = cv2.getPerspectiveTransform(src, dst)\n",
    "    \n",
    "    # Check point\n",
    "    # Showing shape of calculated perspective matrix and its values\n",
    "    print(matrix.shape)  # (3, 3)\n",
    "    print(matrix)\n",
    "    \n",
    "    # Applying perspective transformation\n",
    "    # by found matrix to input image\n",
    "    projected_image = cv2.warpPerspective(input_image, matrix, (height, width))\n",
    "    \n",
    "    # Returning projected image\n",
    "    return projected_image\n",
    "\n",
    "\n",
    "# Check point\n",
    "print('Second function to project image is successfully defined')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic function that renders the figure in a jupyter notebook\n",
    "# instead of displaying a figure object\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(perspective_changing_2(x_train[6]).astype('uint8'))\n",
    "\n",
    "# Showing the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Visualizing examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Defining list to collect new images\n",
    "x_temp_rotation = []\n",
    "x_temp_perspective_1 = []\n",
    "x_temp_perspective_2 = []\n",
    "\n",
    "\n",
    "# Iterating first 15 images from loaded dataset\n",
    "# Applying functions for geometric transformations\n",
    "# Adding results into the lists\n",
    "for i in range(15):\n",
    "    x_temp_rotation.append(rotation_changing(x_train[i]))\n",
    "    x_temp_perspective_1.append(perspective_changing_1(x_train[i]))\n",
    "    x_temp_perspective_2.append(perspective_changing_2(x_train[i]))\n",
    "\n",
    "\n",
    "# Converting lists into Numpy arrays\n",
    "x_temp_rotation = np.array(x_temp_rotation)            # Numpy array\n",
    "x_temp_perspective_1 = np.array(x_temp_perspective_1)  # Numpy array\n",
    "x_temp_perspective_2 = np.array(x_temp_perspective_2)  # Numpy array\n",
    "\n",
    "\n",
    "# Check point\n",
    "print('Geometric transformations of the first 15 images are successfully applied')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check points\n",
    "# Showing some pixels' values before and after geometric transformations\n",
    "print('Original pixels values:')\n",
    "print(x_train[0, 24, :10, 0].astype('uint8'))\n",
    "print()\n",
    "print('After rotation')\n",
    "print(x_temp_rotation[0, 24, :10, 0].astype('uint8'))\n",
    "print()\n",
    "print('After projection 1')\n",
    "print(x_temp_perspective_1[0, 24, :10, 0].astype('uint8'))\n",
    "print()\n",
    "print('After projection 2')\n",
    "print(x_temp_perspective_2[0, 24, :10, 0].astype('uint8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Magic function that renders the figure in a jupyter notebook\n",
    "# instead of displaying a figure object\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Setting default size of the plot\n",
    "plt.rcParams['figure.figsize'] = (9.0, 30.0)\n",
    "\n",
    "\n",
    "# Defining a figure object with number of needed subplots\n",
    "# ax is a (15, 4) Numpy array\n",
    "# To access specific subplot we call it by ax[0, 0]\n",
    "figure, ax = plt.subplots(nrows=15, ncols=4)\n",
    "\n",
    "\n",
    "# Plotting 60 examples along 15 rows and 4 columns\n",
    "for i in range(15):\n",
    "    # Plotting original images in the first column\n",
    "    ax[i, 0].imshow(x_train[i].astype('uint8'))\n",
    "    \n",
    "    # Plotting rotated images in the second column\n",
    "    ax[i, 1].imshow(x_temp_rotation[i].astype('uint8'))\n",
    "    \n",
    "    # Plotting projected images in the third column\n",
    "    ax[i, 2].imshow(x_temp_perspective_1[i].astype('uint8'))\n",
    "    \n",
    "    # Plotting projected images in the fourth column\n",
    "    ax[i, 3].imshow(x_temp_perspective_2[i].astype('uint8'))\n",
    "    \n",
    "    # Hiding axes\n",
    "    ax[i, 0].axis('off')\n",
    "    ax[i, 1].axis('off')\n",
    "    ax[i, 2].axis('off')\n",
    "    ax[i, 3].axis('off')\n",
    "\n",
    "\n",
    "# Giving names to columns\n",
    "ax[0, 0].set_title('Original', fontsize=20)\n",
    "ax[0, 1].set_title('Rotated', fontsize=20)\n",
    "ax[0, 2].set_title('Projected_1', fontsize=20)\n",
    "ax[0, 3].set_title('Projected_2', fontsize=20)\n",
    "\n",
    "\n",
    "# Adjusting distance between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Showing the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some comments\n",
    "\n",
    "To get more details for usage of 'cv2.getRotationMatrix2D':  \n",
    "**print(help(cv2.getRotationMatrix2D))**\n",
    "  \n",
    "More details and examples are here:  \n",
    " - https://docs.opencv.org/4.5.0/da/d54/group__imgproc__transform.html  \n",
    "\n",
    "\n",
    "To get more details for usage of 'cv2.warpAffine':  \n",
    "**print(help(cv2.warpAffine))**\n",
    "  \n",
    "More details and examples are here:  \n",
    " - https://docs.opencv.org/4.5.0/da/d54/group__imgproc__transform.html  \n",
    "\n",
    "\n",
    "To get more details for usage of 'cv2.getPerspectiveTransform':  \n",
    "**print(help(cv2.getPerspectiveTransform))**\n",
    "  \n",
    "More details and examples are here:  \n",
    " - https://docs.opencv.org/4.5.0/da/d54/group__imgproc__transform.html  \n",
    "\n",
    "\n",
    "To get more details for usage of 'cv2.warpPerspective':  \n",
    "**print(help(cv2.warpPerspective))**\n",
    "  \n",
    "More details and examples are here:  \n",
    " - https://docs.opencv.org/4.5.0/da/d54/group__imgproc__transform.html  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(help(cv2.getRotationMatrix2D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(help(cv2.warpAffine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(help(cv2.getPerspectiveTransform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(help(cv2.warpPerspective))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
