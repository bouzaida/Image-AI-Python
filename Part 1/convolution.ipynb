{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course:  Convolutional Neural Networks for Image Classification\n",
    "\n",
    "## Section-1\n",
    "\n",
    "<span style=\"font-size:14pt\">**Quick Win #1: Convolution**</span>  \n",
    "  \n",
    "<span style=\"font-size:14pt\">**Description:**</span>  \n",
    "<span style=\"font-size:13pt\">*Implement convolution operation to grayscale image*</span>  \n",
    "<span style=\"font-size:13pt\">*Detect edge of the object on image by different filters*</span>  \n",
    "  \n",
    "<span style=\"font-size:13pt\">**File:** *convolution.ipynb*</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:14pt\">**Algorithm:**</span>  \n",
    "  \n",
    "<span style=\"font-size:13pt\">**-->** Reading coloured images</span>  \n",
    "<span style=\"font-size:13pt\">**-->** Converting images to GRAY</span>  \n",
    "<span style=\"font-size:13pt\">**-->** Defining common filters for edge detection</span>  \n",
    "<span style=\"font-size:13pt\">**-->** Finding edges by convolution</span>  \n",
    "  \n",
    "<span style=\"font-size:13pt\">**Result:**\n",
    "Plot with input GRAY images and images with detected edges by different filters</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing needed libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importing library to see calculation progress inside loops in Real Time\n",
    "# To install, use following command: pip install tqdm\n",
    "# Don't forget to activate environment in which you're working\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading PNG, JPG and BMP images by OpenCV library\n",
    "# In this way images are opened already as Numpy arrays\n",
    "\n",
    "# (!) OpenCV by default reads images in BGR format (order of channels)\n",
    "# (!) On Windows, the path might look like following:\n",
    "# r'images\\cat.png'\n",
    "# or:\n",
    "# 'images\\\\cat.png'\n",
    "\n",
    "image1_BGR = cv2.imread('images/cat.png')\n",
    "image2_BGR = cv2.imread('images/horse.jpg')\n",
    "image3_BGR = cv2.imread('images/tiger.bmp')\n",
    "\n",
    "\n",
    "# Check point\n",
    "# Showing type of loaded images\n",
    "print('Type of image1_BGR is:', type(image1_BGR))\n",
    "print('Type of image2_BGR is:', type(image2_BGR))\n",
    "print('Type of image3_BGR is:', type(image3_BGR))\n",
    "\n",
    "\n",
    "# Check point\n",
    "# Showing shapes of loaded images\n",
    "print()\n",
    "print('Shape of image1_BGR is:', image1_BGR.shape)\n",
    "print('Shape of image2_BGR is:', image2_BGR.shape)\n",
    "print('Shape of image3_BGR is:', image3_BGR.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting loaded images into Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting images to GRAY by OpenCV function\n",
    "image1_GRAY = cv2.cvtColor(image1_BGR, cv2.COLOR_BGR2GRAY)\n",
    "image2_GRAY = cv2.cvtColor(image2_BGR, cv2.COLOR_BGR2GRAY)\n",
    "image3_GRAY = cv2.cvtColor(image3_BGR, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "# Check point\n",
    "# Showing shapes of GRAY images\n",
    "print('Shape of image1_GRAY is:', image1_GRAY.shape)\n",
    "print('Shape of image2_GRAY is:', image2_GRAY.shape)\n",
    "print('Shape of image3_GRAY is:', image3_GRAY.shape)\n",
    "\n",
    "\n",
    "# Converting images into GRAY by formula\n",
    "# Y' = 0.299 R + 0.587 G + 0.114 B\n",
    "image11_GRAY = image1_BGR[:, :, 2] * 0.299 + \\\n",
    "               image1_BGR[:, :, 1] * 0.587 + \\\n",
    "               image1_BGR[:, :, 0] * 0.114\n",
    "\n",
    "image22_GRAY = image2_BGR[:, :, 2] * 0.299 + \\\n",
    "               image2_BGR[:, :, 1] * 0.587 + \\\n",
    "               image2_BGR[:, :, 0] * 0.114\n",
    "\n",
    "image33_GRAY = image3_BGR[:, :, 2] * 0.299 + \\\n",
    "               image3_BGR[:, :, 1] * 0.587 + \\\n",
    "               image3_BGR[:, :, 0] * 0.114\n",
    "\n",
    "\n",
    "# Check point\n",
    "# Showing pixels' values after conversion by both ways\n",
    "# Slicing only 10 numbers from first row\n",
    "print()\n",
    "print('Pixels of GRAY image converted by OpenCV:', image1_GRAY[0, :9])\n",
    "print('Pixels of GRAY image converted by formula:', image11_GRAY[0, :9])\n",
    "# Rounding float numbers\n",
    "print('Pixels of GRAY image converted by formula:', \n",
    "      np.around(image11_GRAY[0, :9], decimals=0))\n",
    "# Making float numbers as integers\n",
    "print('Pixels of GRAY image converted by formula:',\n",
    "      np.around(image11_GRAY[0, :9], decimals=0).astype(np.int))\n",
    "\n",
    "\n",
    "# Rounding float numbers and making them as integers for all images\n",
    "image11_GRAY = np.around(image11_GRAY, decimals=0).astype(np.int)\n",
    "image22_GRAY = np.around(image22_GRAY, decimals=0).astype(np.int)\n",
    "image33_GRAY = np.around(image33_GRAY, decimals=0).astype(np.int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting coloured and converted GRAY images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic function that renders the figure in a jupyter notebook\n",
    "# instead of displaying a figure object\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Setting default size of the plot\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "\n",
    "\n",
    "# Defining a figure object with number of needed subplots\n",
    "figure, ax = plt.subplots(nrows=3, ncols=3)\n",
    "# ax is a (3, 3) Numpy array and to access specific subplot we call it by ax[0, 0]\n",
    "\n",
    "\n",
    "# Adjusting first column with coloured images\n",
    "# Converting at the same time images from BGR to RGB\n",
    "ax[0, 0].imshow(cv2.cvtColor(image1_BGR, cv2.COLOR_BGR2RGB))\n",
    "ax[1, 0].imshow(cv2.cvtColor(image2_BGR, cv2.COLOR_BGR2RGB))\n",
    "ax[2, 0].imshow(cv2.cvtColor(image3_BGR, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "\n",
    "# Adjusting second column with GRAY images converted by OpenCV\n",
    "ax[0, 1].imshow(image1_GRAY, cmap=plt.get_cmap('gray'))\n",
    "ax[1, 1].imshow(image2_GRAY, cmap=plt.get_cmap('gray'))\n",
    "ax[2, 1].imshow(image3_GRAY, cmap=plt.get_cmap('gray'))\n",
    "\n",
    "\n",
    "# Adjusting third column with GRAY images converted by formula\n",
    "ax[0, 2].imshow(image11_GRAY, cmap=plt.get_cmap('gray'))\n",
    "ax[1, 2].imshow(image22_GRAY, cmap=plt.get_cmap('gray'))\n",
    "ax[2, 2].imshow(image33_GRAY, cmap=plt.get_cmap('gray'))\n",
    "\n",
    "\n",
    "# Giving names to columns\n",
    "ax[0, 0].set_title('Coloured', fontsize=16)\n",
    "ax[0, 1].set_title('GRAY by OpenCV', fontsize=16)\n",
    "ax[0, 2].set_title('GRAY by formula', fontsize=16)\n",
    "\n",
    "\n",
    "# Hiding axes to all subplots\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax[i, j].axis('off')\n",
    "\n",
    "\n",
    "# Adjusting distance between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Showing the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying convolution to GRAY images by edge detection filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting hyperparameters and applying pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing hyperparameters for convolution\n",
    "# To get convolved image (output feature map) with the same dimension\n",
    "# as input image, it is needed to set following:\n",
    "# filter (kernel) size, f_size = 3 (width and height are equal)\n",
    "# stride (step) for sliding, stride = 1\n",
    "# pad to process boundaries (zero valued frame around image), pad = 1\n",
    "\n",
    "# Output image's dimension is calculated by following equations:\n",
    "# height_out = (height_in - f_size + 2 * pad) / step + 1\n",
    "# width_out = (width_in - f_size + 2 * pad) / step + 1\n",
    "\n",
    "# For instance, input GRAY image is 1280x720 of spatial size (width and height),\n",
    "# then output image (convolved image, feature map) will be as following:\n",
    "# height_out = (720 - 3 + 2 * 1) / 1 + 1 = 720\n",
    "# width_out = (1280 - 3 + 2 * 1) / 1 + 1 = 1280\n",
    "\n",
    "\n",
    "# Applying to GRAY images pad frame with zero values to process boundaries\n",
    "# Using Numpy method 'pad'\n",
    "image1_GRAY_pad = np.pad(image1_GRAY, (1, 1), mode='constant', constant_values=0)\n",
    "image2_GRAY_pad = np.pad(image2_GRAY, (1, 1), mode='constant', constant_values=0)\n",
    "image3_GRAY_pad = np.pad(image3_GRAY, (1, 1), mode='constant', constant_values=0)\n",
    "\n",
    "\n",
    "# Check point\n",
    "# Showing shapes of GRAY images\n",
    "print()\n",
    "print('Shape of image1_GRAY is: {0}. With pad: {1}'.format(image1_GRAY.shape,\n",
    "                                                           image1_GRAY_pad.shape))\n",
    "print('Shape of image2_GRAY is: {0}. With pad: {1}'.format(image2_GRAY.shape,\n",
    "                                                           image2_GRAY_pad.shape))\n",
    "print('Shape of image3_GRAY is: {0}. With pad: {1}'.format(image3_GRAY.shape,\n",
    "                                                           image3_GRAY_pad.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining filters (kernels) for edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting common filters (kernels) with size 3x3 for edge detection\n",
    "\n",
    "# Sobel filter to detect vertical changes on image\n",
    "filter_1 = np.array([[1, 0, -1],\n",
    "                     [2, 0, -2],\n",
    "                     [1, 0, -1]])\n",
    "\n",
    "# Laplacian filter to detect regions with different brightness on image\n",
    "filter_2 = np.array([[0, 1, 0], \n",
    "                     [1, -4, 1], \n",
    "                     [0, 1, 0]])\n",
    "\n",
    "# Prewitt filter to detect vertical changes on image\n",
    "filter_3 = np.array([[1, 0, -1], \n",
    "                     [1, 0, -1], \n",
    "                     [1, 0, -1]])\n",
    "\n",
    "\n",
    "# Check point\n",
    "# Showing shapes of the filters\n",
    "print('Shape of the filter 1 is: {0}'.format(filter_1.shape))\n",
    "print('Shape of the filter 2 is: {0}'.format(filter_2.shape))\n",
    "print('Shape of the filter 3 is: {0}'.format(filter_3.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution operation to GRAY images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing zero valued arrays for convolved output images (feature maps)\n",
    "# Dimensions are the same with input image according to chosen hyperparameters\n",
    "# Passing as argument tuple with needed shape\n",
    "# Extending dimension to store processed images by three filters \n",
    "output_image1_GRAY = np.zeros(tuple([3]) + image1_GRAY.shape)\n",
    "output_image2_GRAY = np.zeros(tuple([3]) + image2_GRAY.shape)\n",
    "output_image3_GRAY = np.zeros(tuple([3]) + image3_GRAY.shape)\n",
    "\n",
    "\n",
    "# Check point\n",
    "# Showing shapes of the output images\n",
    "print('Shape of the output images 1 is: {0}'.format(output_image1_GRAY.shape))\n",
    "print('Shape of the output images 2 is: {0}'.format(output_image2_GRAY.shape))\n",
    "print('Shape of the output images 3 is: {0}'.format(output_image3_GRAY.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing convolution operation to GRAY images\n",
    "\n",
    "# GRAY image 1\n",
    "# Sliding through entire input image (that is with pad frame) by different filters\n",
    "# Wrapping the loop with 'tqdm' in order to see progress in real time\n",
    "for i in tqdm(range(image1_GRAY_pad.shape[0] - 2)):\n",
    "    for j in range(image1_GRAY_pad.shape[1] - 2):\n",
    "        # Extracting (slicing) a 3x3 patch (the same size with filter)\n",
    "        # from input image with pad frame\n",
    "        patch = image1_GRAY_pad[i:i+3, j:j+3]\n",
    "\n",
    "        # Applying elementwise multiplication and summation -\n",
    "        # this is convolution operation\n",
    "        # When we use '*' with matrices, then elementwise multiplication\n",
    "        # will be applied\n",
    "\n",
    "        # With filter_1\n",
    "        output_image1_GRAY[0, i, j] = np.sum(patch * filter_1)\n",
    "        # With filter_2\n",
    "        output_image1_GRAY[1, i, j] = np.sum(patch * filter_2)\n",
    "        # With filter_3\n",
    "        output_image1_GRAY[2, i, j] = np.sum(patch * filter_3)\n",
    "\n",
    "\n",
    "# GRAY image 2\n",
    "# Sliding through entire input image (that is with pad frame) by different filters\n",
    "# Wrapping the loop with 'tqdm' in order to see progress in real time\n",
    "for i in tqdm(range(image2_GRAY_pad.shape[0] - 2)):\n",
    "    for j in range(image2_GRAY_pad.shape[1] - 2):\n",
    "        # Extracting (slicing) a 3x3 patch (the same size with filter)\n",
    "        # from input image with pad frame\n",
    "        patch = image2_GRAY_pad[i:i+3, j:j+3]\n",
    "\n",
    "        # Applying elementwise multiplication and summation -\n",
    "        # this is convolution operation\n",
    "        # When we use '*' with matrices, then elementwise multiplication\n",
    "        # will be applied\n",
    "\n",
    "        # With filter_1\n",
    "        output_image2_GRAY[0, i, j] = np.sum(patch * filter_1)\n",
    "        # With filter_2\n",
    "        output_image2_GRAY[1, i, j] = np.sum(patch * filter_2)\n",
    "        # With filter_3\n",
    "        output_image2_GRAY[2, i, j] = np.sum(patch * filter_3)\n",
    "\n",
    "\n",
    "# GRAY image 3\n",
    "# Sliding through entire input image (that is with pad frame) by different filters\n",
    "# Wrapping the loop with 'tqdm' in order to see progress in real time\n",
    "for i in tqdm(range(image3_GRAY_pad.shape[0] - 2)):\n",
    "    for j in range(image3_GRAY_pad.shape[1] - 2):\n",
    "        # Extracting (slicing) a 3x3 patch (the same size with filter)\n",
    "        # from input image with pad frame\n",
    "        patch = image3_GRAY_pad[i:i+3, j:j+3]\n",
    "\n",
    "        # Applying elementwise multiplication and summation -\n",
    "        # this is convolution operation\n",
    "        # When we use '*' with matrices, then elementwise multiplication\n",
    "        # will be applied\n",
    "\n",
    "        # With filter_1\n",
    "        output_image3_GRAY[0, i, j] = np.sum(patch * filter_1)\n",
    "        # With filter_2\n",
    "        output_image3_GRAY[1, i, j] = np.sum(patch * filter_2)\n",
    "        # With filter_3\n",
    "        output_image3_GRAY[2, i, j] = np.sum(patch * filter_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excluding non-needed values (less than 0 and more than 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check point\n",
    "# Showing pixels' values after convolution\n",
    "# Slicing only 10 numbers from first row\n",
    "print('Pixels of GRAY image 1 convolved by filter 1:',\n",
    "      output_image1_GRAY[0, 1, :10])\n",
    "print('Pixels of GRAY image 1 convolved by filter 1:',\n",
    "      output_image1_GRAY[0, 1, 1270:1280])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To exclude values that are less than 0 and more than 255,\n",
    "# Numpy function 'clip' is applied\n",
    "# It keeps values of np array in the given range\n",
    "# And it replaces non-needed values with boundary numbers\n",
    "output_image1_GRAY = np.clip(output_image1_GRAY, 0, 255)\n",
    "output_image2_GRAY = np.clip(output_image2_GRAY, 0, 255)\n",
    "output_image3_GRAY = np.clip(output_image3_GRAY, 0, 255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check point\n",
    "# Showing pixels' values after excluding non-needed values\n",
    "# Slicing only 10 numbers from first row\n",
    "print('Pixels of GRAY image 1 convolved by filter 1:',\n",
    "      output_image1_GRAY[0, 1, :10])\n",
    "print('Pixels of GRAY image 1 convolved by filter 1:',\n",
    "      output_image1_GRAY[0, 1, 1270:1280])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting resulted images with detected edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Magic function that renders the figure in a jupyter notebook\n",
    "# instead of displaying a figure object\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Setting default size of the plot\n",
    "plt.rcParams['figure.figsize'] = (18.0, 10.0)\n",
    "\n",
    "\n",
    "# Defining a figure object with number of needed subplots\n",
    "figure, ax = plt.subplots(nrows=3, ncols=4)\n",
    "# ax is a (3, 4) Numpy array and to access specific subplot we call it by ax[0, 0]\n",
    "\n",
    "\n",
    "# Adjusting first column with GRAY images\n",
    "ax[0, 0].imshow(image1_GRAY, cmap=plt.get_cmap('gray'))\n",
    "ax[1, 0].imshow(image2_GRAY, cmap=plt.get_cmap('gray'))\n",
    "ax[2, 0].imshow(image3_GRAY, cmap=plt.get_cmap('gray'))\n",
    "\n",
    "\n",
    "# Adjusting second column with edges by filter 1: Sobel-x\n",
    "ax[0, 1].imshow(output_image1_GRAY[0], cmap=plt.get_cmap('gray'))\n",
    "ax[1, 1].imshow(output_image2_GRAY[0], cmap=plt.get_cmap('gray'))\n",
    "ax[2, 1].imshow(output_image3_GRAY[0], cmap=plt.get_cmap('gray'))\n",
    "\n",
    "\n",
    "# Adjusting third column with edges by filter 2: Laplacian\n",
    "ax[0, 2].imshow(output_image1_GRAY[1], cmap=plt.get_cmap('gray'))\n",
    "ax[1, 2].imshow(output_image2_GRAY[1], cmap=plt.get_cmap('gray'))\n",
    "ax[2, 2].imshow(output_image3_GRAY[1], cmap=plt.get_cmap('gray'))\n",
    "\n",
    "\n",
    "# Adjusting fourth column with edges by filter 3: Prewitt-x\n",
    "ax[0, 3].imshow(output_image1_GRAY[2], cmap=plt.get_cmap('gray'))\n",
    "ax[1, 3].imshow(output_image2_GRAY[2], cmap=plt.get_cmap('gray'))\n",
    "ax[2, 3].imshow(output_image3_GRAY[2], cmap=plt.get_cmap('gray'))\n",
    "\n",
    "\n",
    "# Giving names to columns\n",
    "ax[0, 0].set_title('Input GRAY', fontsize=16)\n",
    "ax[0, 1].set_title('Edges by Sobel-x', fontsize=16)\n",
    "ax[0, 2].set_title('Edges by Laplacian', fontsize=16)\n",
    "ax[0, 3].set_title('Edges by Prewitt-x', fontsize=16)\n",
    "\n",
    "\n",
    "# Hiding axes to all subplots\n",
    "for i in range(3):\n",
    "    for j in range(4):\n",
    "        ax[i, j].axis('off')\n",
    "\n",
    "\n",
    "# Adjusting distance between subplots\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(left=0.1, right=0.9, bottom=0.1, top=0.9, wspace=0.1, hspace=0.1)\n",
    "\n",
    "\n",
    "# Saving the plot\n",
    "# (!) On Windows, the path might look like following:\n",
    "# r'images\\plot_convolution.png'\n",
    "# or:\n",
    "# 'images\\\\plot_convolution.png'\n",
    "figure.savefig('images/plot_convolution.png')\n",
    "\n",
    "\n",
    "# Showing the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some comments\n",
    "  \n",
    "<span style=\"font-size:13pt\">**np.clip(array, min, max)**</span>  \n",
    "<span style=\"font-size:13pt\">*Clip the values inside array by a given interval (between min and max)*</span>  \n",
    "<span style=\"font-size:13pt\">*Values outside the interval are clipped to the interval edges*</span>    \n",
    "\n",
    "<span style=\"font-size:13pt\">More details and examples are here:</span>  \n",
    "<span style=\"font-size:13pt\">https://numpy.org/devdocs/reference/generated/numpy.clip.html  </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobel filter to detect horizontal changes on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_4 = np.array([[1, 2, 1],  \n",
    "                     [0, 0, 0],  \n",
    "                     [-1, -2, -1]])\n",
    "\n",
    "filter_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prewitt filter to detect horizontal changes on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_5 = np.array([[1, 1, 1],  \n",
    "                     [0, 0, 0],  \n",
    "                     [-1, -1, -1]])\n",
    "\n",
    "filter_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian blur filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_6 = (1 / 16) * np.array([[1, 2, 1],\n",
    "                                [2, 4, 2],\n",
    "                                [1, 2, 1]])\n",
    "\n",
    "filter_6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
